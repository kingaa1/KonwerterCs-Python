# Generated from Gramatyka_i_tokeny.g4 by ANTLR 4.13.1
# encoding: utf-8
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
	from typing import TextIO
else:
	from typing.io import TextIO

def serializedATN():
    return [
        4,1,47,223,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,2,6,7,
        6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,1,0,5,0,
        28,8,0,10,0,12,0,31,9,0,1,0,1,0,1,1,1,1,1,1,3,1,38,8,1,1,2,1,2,3,
        2,42,8,2,1,2,1,2,1,2,1,2,1,2,1,2,5,2,50,8,2,10,2,12,2,53,9,2,1,2,
        1,2,1,3,1,3,1,3,1,3,1,3,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,
        1,4,1,4,5,4,74,8,4,10,4,12,4,77,9,4,1,4,1,4,1,4,1,4,5,4,83,8,4,10,
        4,12,4,86,9,4,1,4,3,4,89,8,4,1,4,1,4,1,4,1,4,1,4,1,4,5,4,97,8,4,
        10,4,12,4,100,9,4,1,4,1,4,1,4,1,4,1,4,5,4,107,8,4,10,4,12,4,110,
        9,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,
        1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,3,4,136,8,4,1,5,1,5,3,5,140,
        8,5,1,5,1,5,1,5,3,5,145,8,5,1,6,1,6,1,6,1,6,1,7,1,7,1,8,1,8,1,8,
        1,8,1,8,3,8,158,8,8,1,8,1,8,3,8,162,8,8,1,8,1,8,1,8,4,8,167,8,8,
        11,8,12,8,168,1,8,1,8,1,9,1,9,1,10,1,10,1,10,1,11,1,11,1,11,1,11,
        1,11,1,11,1,11,1,11,1,11,1,11,1,11,1,11,3,11,190,8,11,1,11,1,11,
        1,11,1,11,1,11,1,11,1,11,1,11,1,11,1,11,1,11,1,11,1,11,1,11,1,11,
        1,11,1,11,1,11,1,11,1,11,1,11,1,11,1,11,1,11,5,11,216,8,11,10,11,
        12,11,219,9,11,1,12,1,12,1,12,0,1,22,13,0,2,4,6,8,10,12,14,16,18,
        20,22,24,0,6,1,0,17,24,1,0,26,28,2,0,16,16,34,34,1,0,35,37,1,0,38,
        39,1,0,40,43,247,0,29,1,0,0,0,2,37,1,0,0,0,4,41,1,0,0,0,6,56,1,0,
        0,0,8,135,1,0,0,0,10,139,1,0,0,0,12,146,1,0,0,0,14,150,1,0,0,0,16,
        152,1,0,0,0,18,172,1,0,0,0,20,174,1,0,0,0,22,189,1,0,0,0,24,220,
        1,0,0,0,26,28,3,2,1,0,27,26,1,0,0,0,28,31,1,0,0,0,29,27,1,0,0,0,
        29,30,1,0,0,0,30,32,1,0,0,0,31,29,1,0,0,0,32,33,5,0,0,1,33,1,1,0,
        0,0,34,38,3,4,2,0,35,38,3,16,8,0,36,38,3,8,4,0,37,34,1,0,0,0,37,
        35,1,0,0,0,37,36,1,0,0,0,38,3,1,0,0,0,39,42,3,14,7,0,40,42,5,1,0,
        0,41,39,1,0,0,0,41,40,1,0,0,0,42,43,1,0,0,0,43,44,5,2,0,0,44,45,
        5,3,0,0,45,46,5,4,0,0,46,51,5,5,0,0,47,50,3,8,4,0,48,50,3,6,3,0,
        49,47,1,0,0,0,49,48,1,0,0,0,50,53,1,0,0,0,51,49,1,0,0,0,51,52,1,
        0,0,0,52,54,1,0,0,0,53,51,1,0,0,0,54,55,5,6,0,0,55,5,1,0,0,0,56,
        57,5,2,0,0,57,58,5,3,0,0,58,59,5,4,0,0,59,60,5,7,0,0,60,7,1,0,0,
        0,61,62,3,10,5,0,62,63,5,7,0,0,63,136,1,0,0,0,64,65,3,12,6,0,65,
        66,5,7,0,0,66,136,1,0,0,0,67,68,5,8,0,0,68,69,5,3,0,0,69,70,3,20,
        10,0,70,71,5,4,0,0,71,75,5,5,0,0,72,74,3,8,4,0,73,72,1,0,0,0,74,
        77,1,0,0,0,75,73,1,0,0,0,75,76,1,0,0,0,76,78,1,0,0,0,77,75,1,0,0,
        0,78,88,5,6,0,0,79,80,5,9,0,0,80,84,5,5,0,0,81,83,3,8,4,0,82,81,
        1,0,0,0,83,86,1,0,0,0,84,82,1,0,0,0,84,85,1,0,0,0,85,87,1,0,0,0,
        86,84,1,0,0,0,87,89,5,6,0,0,88,79,1,0,0,0,88,89,1,0,0,0,89,136,1,
        0,0,0,90,91,5,10,0,0,91,92,5,3,0,0,92,93,3,20,10,0,93,94,5,4,0,0,
        94,98,5,5,0,0,95,97,3,8,4,0,96,95,1,0,0,0,97,100,1,0,0,0,98,96,1,
        0,0,0,98,99,1,0,0,0,99,101,1,0,0,0,100,98,1,0,0,0,101,102,5,6,0,
        0,102,136,1,0,0,0,103,104,5,11,0,0,104,108,5,5,0,0,105,107,3,8,4,
        0,106,105,1,0,0,0,107,110,1,0,0,0,108,106,1,0,0,0,108,109,1,0,0,
        0,109,111,1,0,0,0,110,108,1,0,0,0,111,112,5,6,0,0,112,113,5,10,0,
        0,113,114,5,3,0,0,114,115,3,20,10,0,115,116,5,4,0,0,116,117,5,7,
        0,0,117,136,1,0,0,0,118,119,5,12,0,0,119,120,5,3,0,0,120,121,3,10,
        5,0,121,122,5,7,0,0,122,123,3,20,10,0,123,124,5,7,0,0,124,125,3,
        20,10,0,125,126,5,4,0,0,126,127,3,8,4,0,127,136,1,0,0,0,128,129,
        5,13,0,0,129,130,3,20,10,0,130,131,5,7,0,0,131,136,1,0,0,0,132,133,
        3,20,10,0,133,134,5,7,0,0,134,136,1,0,0,0,135,61,1,0,0,0,135,64,
        1,0,0,0,135,67,1,0,0,0,135,90,1,0,0,0,135,103,1,0,0,0,135,118,1,
        0,0,0,135,128,1,0,0,0,135,132,1,0,0,0,136,9,1,0,0,0,137,140,3,14,
        7,0,138,140,5,14,0,0,139,137,1,0,0,0,139,138,1,0,0,0,140,141,1,0,
        0,0,141,144,5,2,0,0,142,143,5,15,0,0,143,145,3,20,10,0,144,142,1,
        0,0,0,144,145,1,0,0,0,145,11,1,0,0,0,146,147,5,2,0,0,147,148,5,16,
        0,0,148,149,3,20,10,0,149,13,1,0,0,0,150,151,7,0,0,0,151,15,1,0,
        0,0,152,153,3,18,9,0,153,154,5,25,0,0,154,155,5,2,0,0,155,166,5,
        5,0,0,156,158,3,18,9,0,157,156,1,0,0,0,157,158,1,0,0,0,158,159,1,
        0,0,0,159,167,3,4,2,0,160,162,3,18,9,0,161,160,1,0,0,0,161,162,1,
        0,0,0,162,163,1,0,0,0,163,164,3,10,5,0,164,165,5,7,0,0,165,167,1,
        0,0,0,166,157,1,0,0,0,166,161,1,0,0,0,167,168,1,0,0,0,168,166,1,
        0,0,0,168,169,1,0,0,0,169,170,1,0,0,0,170,171,5,6,0,0,171,17,1,0,
        0,0,172,173,7,1,0,0,173,19,1,0,0,0,174,175,3,22,11,0,175,176,5,7,
        0,0,176,21,1,0,0,0,177,178,6,11,-1,0,178,179,5,3,0,0,179,180,3,22,
        11,0,180,181,5,4,0,0,181,190,1,0,0,0,182,183,5,29,0,0,183,190,3,
        22,11,14,184,190,5,30,0,0,185,190,5,31,0,0,186,190,5,32,0,0,187,
        190,5,33,0,0,188,190,5,2,0,0,189,177,1,0,0,0,189,182,1,0,0,0,189,
        184,1,0,0,0,189,185,1,0,0,0,189,186,1,0,0,0,189,187,1,0,0,0,189,
        188,1,0,0,0,190,217,1,0,0,0,191,192,10,13,0,0,192,193,7,2,0,0,193,
        216,3,22,11,14,194,195,10,12,0,0,195,196,7,3,0,0,196,216,3,22,11,
        13,197,198,10,11,0,0,198,199,7,4,0,0,199,216,3,22,11,12,200,201,
        10,10,0,0,201,202,7,5,0,0,202,216,3,22,11,11,203,204,10,9,0,0,204,
        205,5,44,0,0,205,216,3,22,11,10,206,207,10,8,0,0,207,208,5,45,0,
        0,208,216,3,22,11,9,209,210,10,7,0,0,210,211,5,46,0,0,211,216,3,
        22,11,8,212,213,10,6,0,0,213,214,5,47,0,0,214,216,3,22,11,7,215,
        191,1,0,0,0,215,194,1,0,0,0,215,197,1,0,0,0,215,200,1,0,0,0,215,
        203,1,0,0,0,215,206,1,0,0,0,215,209,1,0,0,0,215,212,1,0,0,0,216,
        219,1,0,0,0,217,215,1,0,0,0,217,218,1,0,0,0,218,23,1,0,0,0,219,217,
        1,0,0,0,220,221,5,2,0,0,221,25,1,0,0,0,20,29,37,41,49,51,75,84,88,
        98,108,135,139,144,157,161,166,168,189,215,217
    ]

class Gramatyka_i_tokenyParser ( Parser ):

    grammarFileName = "Gramatyka_i_tokeny.g4"

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    sharedContextCache = PredictionContextCache()

    literalNames = [  ]

    symbolicNames = [ "<INVALID>", "VOID", "IDENTIFIER", "LEFTROUND", "RIGHTROUND", 
                        "LEFTCURLY", "RIGHTCURLY", "SEMICOLON", "IF", "ELSE", 
                        "WHILE", "DO", "FOR", "RETURN", "VAR", "EQUALS", "EQUAL", 
                        "BOOL", "DECIMAL", "SHORT", "CHAR", "INT", "LONG", 
                        "FLOAT", "DOUBLE", "CLASS", "PUBLIC", "PROTECTED", 
                        "PRIVATE", "NOT", "INTLIT", "FLOATLIT", "BOOLLIT", 
                        "CHARLIT", "NOTEQUAL", "MULT", "DIV", "MOD", "ADD", 
                        "SUB", "LESS", "LESSOREQUAL", "GREATER", "GREATEROREQUAL", 
                        "AND", "OR", "ASSIGN", "COMMA" ]

    RULE_program = 0
    RULE_declaration = 1
    RULE_function_definition = 2
    RULE_function_declaration = 3
    RULE_statement = 4
    RULE_variable_declaration = 5
    RULE_variable_assignment = 6
    RULE_variable_type = 7
    RULE_class_definition = 8
    RULE_all_member_modifier = 9
    RULE_expression = 10
    RULE_value = 11
    RULE_identifier = 12

    ruleNames =  [ "program", "declaration", "function_definition", "function_declaration", 
                    "statement", "variable_declaration", "variable_assignment", 
                    "variable_type", "class_definition", "all_member_modifier", 
                    "expression", "value", "identifier" ]

    EOF = Token.EOF
    VOID=1
    IDENTIFIER=2
    LEFTROUND=3
    RIGHTROUND=4
    LEFTCURLY=5
    RIGHTCURLY=6
    SEMICOLON=7
    IF=8
    ELSE=9
    WHILE=10
    DO=11
    FOR=12
    RETURN=13
    VAR=14
    EQUALS=15
    EQUAL=16
    BOOL=17
    DECIMAL=18
    SHORT=19
    CHAR=20
    INT=21
    LONG=22
    FLOAT=23
    DOUBLE=24
    CLASS=25
    PUBLIC=26
    PROTECTED=27
    PRIVATE=28
    NOT=29
    INTLIT=30
    FLOATLIT=31
    BOOLLIT=32
    CHARLIT=33
    NOTEQUAL=34
    MULT=35
    DIV=36
    MOD=37
    ADD=38
    SUB=39
    LESS=40
    LESSOREQUAL=41
    GREATER=42
    GREATEROREQUAL=43
    AND=44
    OR=45
    ASSIGN=46
    COMMA=47

    def __init__(self, input:TokenStream, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.13.1")
        self._interp = ParserATNSimulator(self, self.atn, self.decisionsToDFA, self.sharedContextCache)
        self._predicates = None




    class ProgramContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def EOF(self):
            return self.getToken(Gramatyka_i_tokenyParser.EOF, 0)

        def declaration(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(Gramatyka_i_tokenyParser.DeclarationContext)
            else:
                return self.getTypedRuleContext(Gramatyka_i_tokenyParser.DeclarationContext,i)


        def getRuleIndex(self):
            return Gramatyka_i_tokenyParser.RULE_program

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterProgram" ):
                listener.enterProgram(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitProgram" ):
                listener.exitProgram(self)




    def program(self):

        localctx = Gramatyka_i_tokenyParser.ProgramContext(self, self._ctx, self.state)
        self.enterRule(localctx, 0, self.RULE_program)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 29
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & 17146215694) != 0):
                self.state = 26
                self.declaration()
                self.state = 31
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 32
            self.match(Gramatyka_i_tokenyParser.EOF)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class DeclarationContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def function_definition(self):
            return self.getTypedRuleContext(Gramatyka_i_tokenyParser.Function_definitionContext,0)


        def class_definition(self):
            return self.getTypedRuleContext(Gramatyka_i_tokenyParser.Class_definitionContext,0)


        def statement(self):
            return self.getTypedRuleContext(Gramatyka_i_tokenyParser.StatementContext,0)


        def getRuleIndex(self):
            return Gramatyka_i_tokenyParser.RULE_declaration

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterDeclaration" ):
                listener.enterDeclaration(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitDeclaration" ):
                listener.exitDeclaration(self)




    def declaration(self):

        localctx = Gramatyka_i_tokenyParser.DeclarationContext(self, self._ctx, self.state)
        self.enterRule(localctx, 2, self.RULE_declaration)
        try:
            self.state = 37
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,1,self._ctx)
            if la_ == 1:
                self.enterOuterAlt(localctx, 1)
                self.state = 34
                self.function_definition()
                pass

            elif la_ == 2:
                self.enterOuterAlt(localctx, 2)
                self.state = 35
                self.class_definition()
                pass

            elif la_ == 3:
                self.enterOuterAlt(localctx, 3)
                self.state = 36
                self.statement()
                pass


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Function_definitionContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def IDENTIFIER(self):
            return self.getToken(Gramatyka_i_tokenyParser.IDENTIFIER, 0)

        def LEFTROUND(self):
            return self.getToken(Gramatyka_i_tokenyParser.LEFTROUND, 0)

        def RIGHTROUND(self):
            return self.getToken(Gramatyka_i_tokenyParser.RIGHTROUND, 0)

        def LEFTCURLY(self):
            return self.getToken(Gramatyka_i_tokenyParser.LEFTCURLY, 0)

        def RIGHTCURLY(self):
            return self.getToken(Gramatyka_i_tokenyParser.RIGHTCURLY, 0)

        def variable_type(self):
            return self.getTypedRuleContext(Gramatyka_i_tokenyParser.Variable_typeContext,0)


        def VOID(self):
            return self.getToken(Gramatyka_i_tokenyParser.VOID, 0)

        def statement(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(Gramatyka_i_tokenyParser.StatementContext)
            else:
                return self.getTypedRuleContext(Gramatyka_i_tokenyParser.StatementContext,i)


        def function_declaration(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(Gramatyka_i_tokenyParser.Function_declarationContext)
            else:
                return self.getTypedRuleContext(Gramatyka_i_tokenyParser.Function_declarationContext,i)


        def getRuleIndex(self):
            return Gramatyka_i_tokenyParser.RULE_function_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterFunction_definition" ):
                listener.enterFunction_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitFunction_definition" ):
                listener.exitFunction_definition(self)




    def function_definition(self):

        localctx = Gramatyka_i_tokenyParser.Function_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 4, self.RULE_function_definition)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 41
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [17, 18, 19, 20, 21, 22, 23, 24]:
                self.state = 39
                self.variable_type()
                pass
            elif token in [1]:
                self.state = 40
                self.match(Gramatyka_i_tokenyParser.VOID)
                pass
            else:
                raise NoViableAltException(self)

            self.state = 43
            self.match(Gramatyka_i_tokenyParser.IDENTIFIER)
            self.state = 44
            self.match(Gramatyka_i_tokenyParser.LEFTROUND)
            self.state = 45
            self.match(Gramatyka_i_tokenyParser.RIGHTROUND)
            self.state = 46
            self.match(Gramatyka_i_tokenyParser.LEFTCURLY)
            self.state = 51
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & 16676453644) != 0):
                self.state = 49
                self._errHandler.sync(self)
                la_ = self._interp.adaptivePredict(self._input,3,self._ctx)
                if la_ == 1:
                    self.state = 47
                    self.statement()
                    pass

                elif la_ == 2:
                    self.state = 48
                    self.function_declaration()
                    pass


                self.state = 53
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 54
            self.match(Gramatyka_i_tokenyParser.RIGHTCURLY)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Function_declarationContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def IDENTIFIER(self):
            return self.getToken(Gramatyka_i_tokenyParser.IDENTIFIER, 0)

        def LEFTROUND(self):
            return self.getToken(Gramatyka_i_tokenyParser.LEFTROUND, 0)

        def RIGHTROUND(self):
            return self.getToken(Gramatyka_i_tokenyParser.RIGHTROUND, 0)

        def SEMICOLON(self):
            return self.getToken(Gramatyka_i_tokenyParser.SEMICOLON, 0)

        def getRuleIndex(self):
            return Gramatyka_i_tokenyParser.RULE_function_declaration

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterFunction_declaration" ):
                listener.enterFunction_declaration(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitFunction_declaration" ):
                listener.exitFunction_declaration(self)




    def function_declaration(self):

        localctx = Gramatyka_i_tokenyParser.Function_declarationContext(self, self._ctx, self.state)
        self.enterRule(localctx, 6, self.RULE_function_declaration)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 56
            self.match(Gramatyka_i_tokenyParser.IDENTIFIER)
            self.state = 57
            self.match(Gramatyka_i_tokenyParser.LEFTROUND)
            self.state = 58
            self.match(Gramatyka_i_tokenyParser.RIGHTROUND)
            self.state = 59
            self.match(Gramatyka_i_tokenyParser.SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class StatementContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def variable_declaration(self):
            return self.getTypedRuleContext(Gramatyka_i_tokenyParser.Variable_declarationContext,0)


        def SEMICOLON(self, i:int=None):
            if i is None:
                return self.getTokens(Gramatyka_i_tokenyParser.SEMICOLON)
            else:
                return self.getToken(Gramatyka_i_tokenyParser.SEMICOLON, i)

        def variable_assignment(self):
            return self.getTypedRuleContext(Gramatyka_i_tokenyParser.Variable_assignmentContext,0)


        def IF(self):
            return self.getToken(Gramatyka_i_tokenyParser.IF, 0)

        def LEFTROUND(self):
            return self.getToken(Gramatyka_i_tokenyParser.LEFTROUND, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(Gramatyka_i_tokenyParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(Gramatyka_i_tokenyParser.ExpressionContext,i)


        def RIGHTROUND(self):
            return self.getToken(Gramatyka_i_tokenyParser.RIGHTROUND, 0)

        def LEFTCURLY(self, i:int=None):
            if i is None:
                return self.getTokens(Gramatyka_i_tokenyParser.LEFTCURLY)
            else:
                return self.getToken(Gramatyka_i_tokenyParser.LEFTCURLY, i)

        def RIGHTCURLY(self, i:int=None):
            if i is None:
                return self.getTokens(Gramatyka_i_tokenyParser.RIGHTCURLY)
            else:
                return self.getToken(Gramatyka_i_tokenyParser.RIGHTCURLY, i)

        def statement(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(Gramatyka_i_tokenyParser.StatementContext)
            else:
                return self.getTypedRuleContext(Gramatyka_i_tokenyParser.StatementContext,i)


        def ELSE(self):
            return self.getToken(Gramatyka_i_tokenyParser.ELSE, 0)

        def WHILE(self):
            return self.getToken(Gramatyka_i_tokenyParser.WHILE, 0)

        def DO(self):
            return self.getToken(Gramatyka_i_tokenyParser.DO, 0)

        def FOR(self):
            return self.getToken(Gramatyka_i_tokenyParser.FOR, 0)

        def RETURN(self):
            return self.getToken(Gramatyka_i_tokenyParser.RETURN, 0)

        def getRuleIndex(self):
            return Gramatyka_i_tokenyParser.RULE_statement

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterStatement" ):
                listener.enterStatement(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitStatement" ):
                listener.exitStatement(self)




    def statement(self):

        localctx = Gramatyka_i_tokenyParser.StatementContext(self, self._ctx, self.state)
        self.enterRule(localctx, 8, self.RULE_statement)
        self._la = 0 # Token type
        try:
            self.state = 135
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,10,self._ctx)
            if la_ == 1:
                self.enterOuterAlt(localctx, 1)
                self.state = 61
                self.variable_declaration()
                self.state = 62
                self.match(Gramatyka_i_tokenyParser.SEMICOLON)
                pass

            elif la_ == 2:
                self.enterOuterAlt(localctx, 2)
                self.state = 64
                self.variable_assignment()
                self.state = 65
                self.match(Gramatyka_i_tokenyParser.SEMICOLON)
                pass

            elif la_ == 3:
                self.enterOuterAlt(localctx, 3)
                self.state = 67
                self.match(Gramatyka_i_tokenyParser.IF)
                self.state = 68
                self.match(Gramatyka_i_tokenyParser.LEFTROUND)
                self.state = 69
                self.expression()
                self.state = 70
                self.match(Gramatyka_i_tokenyParser.RIGHTROUND)
                self.state = 71
                self.match(Gramatyka_i_tokenyParser.LEFTCURLY)
                self.state = 75
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                while (((_la) & ~0x3f) == 0 and ((1 << _la) & 16676453644) != 0):
                    self.state = 72
                    self.statement()
                    self.state = 77
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)

                self.state = 78
                self.match(Gramatyka_i_tokenyParser.RIGHTCURLY)
                self.state = 88
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if _la==9:
                    self.state = 79
                    self.match(Gramatyka_i_tokenyParser.ELSE)
                    self.state = 80
                    self.match(Gramatyka_i_tokenyParser.LEFTCURLY)
                    self.state = 84
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)
                    while (((_la) & ~0x3f) == 0 and ((1 << _la) & 16676453644) != 0):
                        self.state = 81
                        self.statement()
                        self.state = 86
                        self._errHandler.sync(self)
                        _la = self._input.LA(1)

                    self.state = 87
                    self.match(Gramatyka_i_tokenyParser.RIGHTCURLY)


                pass

            elif la_ == 4:
                self.enterOuterAlt(localctx, 4)
                self.state = 90
                self.match(Gramatyka_i_tokenyParser.WHILE)
                self.state = 91
                self.match(Gramatyka_i_tokenyParser.LEFTROUND)
                self.state = 92
                self.expression()
                self.state = 93
                self.match(Gramatyka_i_tokenyParser.RIGHTROUND)
                self.state = 94
                self.match(Gramatyka_i_tokenyParser.LEFTCURLY)
                self.state = 98
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                while (((_la) & ~0x3f) == 0 and ((1 << _la) & 16676453644) != 0):
                    self.state = 95
                    self.statement()
                    self.state = 100
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)

                self.state = 101
                self.match(Gramatyka_i_tokenyParser.RIGHTCURLY)
                pass

            elif la_ == 5:
                self.enterOuterAlt(localctx, 5)
                self.state = 103
                self.match(Gramatyka_i_tokenyParser.DO)
                self.state = 104
                self.match(Gramatyka_i_tokenyParser.LEFTCURLY)
                self.state = 108
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                while (((_la) & ~0x3f) == 0 and ((1 << _la) & 16676453644) != 0):
                    self.state = 105
                    self.statement()
                    self.state = 110
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)

                self.state = 111
                self.match(Gramatyka_i_tokenyParser.RIGHTCURLY)
                self.state = 112
                self.match(Gramatyka_i_tokenyParser.WHILE)
                self.state = 113
                self.match(Gramatyka_i_tokenyParser.LEFTROUND)
                self.state = 114
                self.expression()
                self.state = 115
                self.match(Gramatyka_i_tokenyParser.RIGHTROUND)
                self.state = 116
                self.match(Gramatyka_i_tokenyParser.SEMICOLON)
                pass

            elif la_ == 6:
                self.enterOuterAlt(localctx, 6)
                self.state = 118
                self.match(Gramatyka_i_tokenyParser.FOR)
                self.state = 119
                self.match(Gramatyka_i_tokenyParser.LEFTROUND)
                self.state = 120
                self.variable_declaration()
                self.state = 121
                self.match(Gramatyka_i_tokenyParser.SEMICOLON)
                self.state = 122
                self.expression()
                self.state = 123
                self.match(Gramatyka_i_tokenyParser.SEMICOLON)
                self.state = 124
                self.expression()
                self.state = 125
                self.match(Gramatyka_i_tokenyParser.RIGHTROUND)
                self.state = 126
                self.statement()
                pass

            elif la_ == 7:
                self.enterOuterAlt(localctx, 7)
                self.state = 128
                self.match(Gramatyka_i_tokenyParser.RETURN)
                self.state = 129
                self.expression()
                self.state = 130
                self.match(Gramatyka_i_tokenyParser.SEMICOLON)
                pass

            elif la_ == 8:
                self.enterOuterAlt(localctx, 8)
                self.state = 132
                self.expression()
                self.state = 133
                self.match(Gramatyka_i_tokenyParser.SEMICOLON)
                pass


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Variable_declarationContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def IDENTIFIER(self):
            return self.getToken(Gramatyka_i_tokenyParser.IDENTIFIER, 0)

        def variable_type(self):
            return self.getTypedRuleContext(Gramatyka_i_tokenyParser.Variable_typeContext,0)


        def VAR(self):
            return self.getToken(Gramatyka_i_tokenyParser.VAR, 0)

        def EQUALS(self):
            return self.getToken(Gramatyka_i_tokenyParser.EQUALS, 0)

        def expression(self):
            return self.getTypedRuleContext(Gramatyka_i_tokenyParser.ExpressionContext,0)


        def getRuleIndex(self):
            return Gramatyka_i_tokenyParser.RULE_variable_declaration

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterVariable_declaration" ):
                listener.enterVariable_declaration(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitVariable_declaration" ):
                listener.exitVariable_declaration(self)




    def variable_declaration(self):

        localctx = Gramatyka_i_tokenyParser.Variable_declarationContext(self, self._ctx, self.state)
        self.enterRule(localctx, 10, self.RULE_variable_declaration)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 139
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [17, 18, 19, 20, 21, 22, 23, 24]:
                self.state = 137
                self.variable_type()
                pass
            elif token in [14]:
                self.state = 138
                self.match(Gramatyka_i_tokenyParser.VAR)
                pass
            else:
                raise NoViableAltException(self)

            self.state = 141
            self.match(Gramatyka_i_tokenyParser.IDENTIFIER)
            self.state = 144
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==15:
                self.state = 142
                self.match(Gramatyka_i_tokenyParser.EQUALS)
                self.state = 143
                self.expression()


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Variable_assignmentContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def IDENTIFIER(self):
            return self.getToken(Gramatyka_i_tokenyParser.IDENTIFIER, 0)

        def EQUAL(self):
            return self.getToken(Gramatyka_i_tokenyParser.EQUAL, 0)

        def expression(self):
            return self.getTypedRuleContext(Gramatyka_i_tokenyParser.ExpressionContext,0)


        def getRuleIndex(self):
            return Gramatyka_i_tokenyParser.RULE_variable_assignment

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterVariable_assignment" ):
                listener.enterVariable_assignment(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitVariable_assignment" ):
                listener.exitVariable_assignment(self)




    def variable_assignment(self):

        localctx = Gramatyka_i_tokenyParser.Variable_assignmentContext(self, self._ctx, self.state)
        self.enterRule(localctx, 12, self.RULE_variable_assignment)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 146
            self.match(Gramatyka_i_tokenyParser.IDENTIFIER)
            self.state = 147
            self.match(Gramatyka_i_tokenyParser.EQUAL)
            self.state = 148
            self.expression()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Variable_typeContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def BOOL(self):
            return self.getToken(Gramatyka_i_tokenyParser.BOOL, 0)

        def DECIMAL(self):
            return self.getToken(Gramatyka_i_tokenyParser.DECIMAL, 0)

        def SHORT(self):
            return self.getToken(Gramatyka_i_tokenyParser.SHORT, 0)

        def CHAR(self):
            return self.getToken(Gramatyka_i_tokenyParser.CHAR, 0)

        def INT(self):
            return self.getToken(Gramatyka_i_tokenyParser.INT, 0)

        def LONG(self):
            return self.getToken(Gramatyka_i_tokenyParser.LONG, 0)

        def FLOAT(self):
            return self.getToken(Gramatyka_i_tokenyParser.FLOAT, 0)

        def DOUBLE(self):
            return self.getToken(Gramatyka_i_tokenyParser.DOUBLE, 0)

        def getRuleIndex(self):
            return Gramatyka_i_tokenyParser.RULE_variable_type

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterVariable_type" ):
                listener.enterVariable_type(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitVariable_type" ):
                listener.exitVariable_type(self)




    def variable_type(self):

        localctx = Gramatyka_i_tokenyParser.Variable_typeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 14, self.RULE_variable_type)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 150
            _la = self._input.LA(1)
            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & 33423360) != 0)):
                self._errHandler.recoverInline(self)
            else:
                self._errHandler.reportMatch(self)
                self.consume()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Class_definitionContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def all_member_modifier(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(Gramatyka_i_tokenyParser.All_member_modifierContext)
            else:
                return self.getTypedRuleContext(Gramatyka_i_tokenyParser.All_member_modifierContext,i)


        def CLASS(self):
            return self.getToken(Gramatyka_i_tokenyParser.CLASS, 0)

        def IDENTIFIER(self):
            return self.getToken(Gramatyka_i_tokenyParser.IDENTIFIER, 0)

        def LEFTCURLY(self):
            return self.getToken(Gramatyka_i_tokenyParser.LEFTCURLY, 0)

        def RIGHTCURLY(self):
            return self.getToken(Gramatyka_i_tokenyParser.RIGHTCURLY, 0)

        def function_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(Gramatyka_i_tokenyParser.Function_definitionContext)
            else:
                return self.getTypedRuleContext(Gramatyka_i_tokenyParser.Function_definitionContext,i)


        def variable_declaration(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(Gramatyka_i_tokenyParser.Variable_declarationContext)
            else:
                return self.getTypedRuleContext(Gramatyka_i_tokenyParser.Variable_declarationContext,i)


        def SEMICOLON(self, i:int=None):
            if i is None:
                return self.getTokens(Gramatyka_i_tokenyParser.SEMICOLON)
            else:
                return self.getToken(Gramatyka_i_tokenyParser.SEMICOLON, i)

        def getRuleIndex(self):
            return Gramatyka_i_tokenyParser.RULE_class_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterClass_definition" ):
                listener.enterClass_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitClass_definition" ):
                listener.exitClass_definition(self)




    def class_definition(self):

        localctx = Gramatyka_i_tokenyParser.Class_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 16, self.RULE_class_definition)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 152
            self.all_member_modifier()
            self.state = 153
            self.match(Gramatyka_i_tokenyParser.CLASS)
            self.state = 154
            self.match(Gramatyka_i_tokenyParser.IDENTIFIER)
            self.state = 155
            self.match(Gramatyka_i_tokenyParser.LEFTCURLY)
            self.state = 166 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 166
                self._errHandler.sync(self)
                la_ = self._interp.adaptivePredict(self._input,15,self._ctx)
                if la_ == 1:
                    self.state = 157
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)
                    if (((_la) & ~0x3f) == 0 and ((1 << _la) & 469762048) != 0):
                        self.state = 156
                        self.all_member_modifier()


                    self.state = 159
                    self.function_definition()
                    pass

                elif la_ == 2:
                    self.state = 161
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)
                    if (((_la) & ~0x3f) == 0 and ((1 << _la) & 469762048) != 0):
                        self.state = 160
                        self.all_member_modifier()


                    self.state = 163
                    self.variable_declaration()
                    self.state = 164
                    self.match(Gramatyka_i_tokenyParser.SEMICOLON)
                    pass


                self.state = 168 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & 503201794) != 0)):
                    break

            self.state = 170
            self.match(Gramatyka_i_tokenyParser.RIGHTCURLY)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class All_member_modifierContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def PUBLIC(self):
            return self.getToken(Gramatyka_i_tokenyParser.PUBLIC, 0)

        def PROTECTED(self):
            return self.getToken(Gramatyka_i_tokenyParser.PROTECTED, 0)

        def PRIVATE(self):
            return self.getToken(Gramatyka_i_tokenyParser.PRIVATE, 0)

        def getRuleIndex(self):
            return Gramatyka_i_tokenyParser.RULE_all_member_modifier

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterAll_member_modifier" ):
                listener.enterAll_member_modifier(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitAll_member_modifier" ):
                listener.exitAll_member_modifier(self)




    def all_member_modifier(self):

        localctx = Gramatyka_i_tokenyParser.All_member_modifierContext(self, self._ctx, self.state)
        self.enterRule(localctx, 18, self.RULE_all_member_modifier)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 172
            _la = self._input.LA(1)
            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & 469762048) != 0)):
                self._errHandler.recoverInline(self)
            else:
                self._errHandler.reportMatch(self)
                self.consume()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ExpressionContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def value(self):
            return self.getTypedRuleContext(Gramatyka_i_tokenyParser.ValueContext,0)


        def SEMICOLON(self):
            return self.getToken(Gramatyka_i_tokenyParser.SEMICOLON, 0)

        def getRuleIndex(self):
            return Gramatyka_i_tokenyParser.RULE_expression

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterExpression" ):
                listener.enterExpression(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitExpression" ):
                listener.exitExpression(self)




    def expression(self):

        localctx = Gramatyka_i_tokenyParser.ExpressionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 20, self.RULE_expression)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 174
            self.value(0)
            self.state = 175
            self.match(Gramatyka_i_tokenyParser.SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ValueContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def LEFTROUND(self):
            return self.getToken(Gramatyka_i_tokenyParser.LEFTROUND, 0)

        def value(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(Gramatyka_i_tokenyParser.ValueContext)
            else:
                return self.getTypedRuleContext(Gramatyka_i_tokenyParser.ValueContext,i)


        def RIGHTROUND(self):
            return self.getToken(Gramatyka_i_tokenyParser.RIGHTROUND, 0)

        def NOT(self):
            return self.getToken(Gramatyka_i_tokenyParser.NOT, 0)

        def INTLIT(self):
            return self.getToken(Gramatyka_i_tokenyParser.INTLIT, 0)

        def FLOATLIT(self):
            return self.getToken(Gramatyka_i_tokenyParser.FLOATLIT, 0)

        def BOOLLIT(self):
            return self.getToken(Gramatyka_i_tokenyParser.BOOLLIT, 0)

        def CHARLIT(self):
            return self.getToken(Gramatyka_i_tokenyParser.CHARLIT, 0)

        def IDENTIFIER(self):
            return self.getToken(Gramatyka_i_tokenyParser.IDENTIFIER, 0)

        def EQUAL(self):
            return self.getToken(Gramatyka_i_tokenyParser.EQUAL, 0)

        def NOTEQUAL(self):
            return self.getToken(Gramatyka_i_tokenyParser.NOTEQUAL, 0)

        def MULT(self):
            return self.getToken(Gramatyka_i_tokenyParser.MULT, 0)

        def DIV(self):
            return self.getToken(Gramatyka_i_tokenyParser.DIV, 0)

        def MOD(self):
            return self.getToken(Gramatyka_i_tokenyParser.MOD, 0)

        def ADD(self):
            return self.getToken(Gramatyka_i_tokenyParser.ADD, 0)

        def SUB(self):
            return self.getToken(Gramatyka_i_tokenyParser.SUB, 0)

        def LESS(self):
            return self.getToken(Gramatyka_i_tokenyParser.LESS, 0)

        def LESSOREQUAL(self):
            return self.getToken(Gramatyka_i_tokenyParser.LESSOREQUAL, 0)

        def GREATER(self):
            return self.getToken(Gramatyka_i_tokenyParser.GREATER, 0)

        def GREATEROREQUAL(self):
            return self.getToken(Gramatyka_i_tokenyParser.GREATEROREQUAL, 0)

        def AND(self):
            return self.getToken(Gramatyka_i_tokenyParser.AND, 0)

        def OR(self):
            return self.getToken(Gramatyka_i_tokenyParser.OR, 0)

        def ASSIGN(self):
            return self.getToken(Gramatyka_i_tokenyParser.ASSIGN, 0)

        def COMMA(self):
            return self.getToken(Gramatyka_i_tokenyParser.COMMA, 0)

        def getRuleIndex(self):
            return Gramatyka_i_tokenyParser.RULE_value

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterValue" ):
                listener.enterValue(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitValue" ):
                listener.exitValue(self)



    def value(self, _p:int=0):
        _parentctx = self._ctx
        _parentState = self.state
        localctx = Gramatyka_i_tokenyParser.ValueContext(self, self._ctx, _parentState)
        _prevctx = localctx
        _startState = 22
        self.enterRecursionRule(localctx, 22, self.RULE_value, _p)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 189
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [3]:
                self.state = 178
                self.match(Gramatyka_i_tokenyParser.LEFTROUND)
                self.state = 179
                self.value(0)
                self.state = 180
                self.match(Gramatyka_i_tokenyParser.RIGHTROUND)
                pass
            elif token in [29]:
                self.state = 182
                self.match(Gramatyka_i_tokenyParser.NOT)
                self.state = 183
                self.value(14)
                pass
            elif token in [30]:
                self.state = 184
                self.match(Gramatyka_i_tokenyParser.INTLIT)
                pass
            elif token in [31]:
                self.state = 185
                self.match(Gramatyka_i_tokenyParser.FLOATLIT)
                pass
            elif token in [32]:
                self.state = 186
                self.match(Gramatyka_i_tokenyParser.BOOLLIT)
                pass
            elif token in [33]:
                self.state = 187
                self.match(Gramatyka_i_tokenyParser.CHARLIT)
                pass
            elif token in [2]:
                self.state = 188
                self.match(Gramatyka_i_tokenyParser.IDENTIFIER)
                pass
            else:
                raise NoViableAltException(self)

            self._ctx.stop = self._input.LT(-1)
            self.state = 217
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,19,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    if self._parseListeners is not None:
                        self.triggerExitRuleEvent()
                    _prevctx = localctx
                    self.state = 215
                    self._errHandler.sync(self)
                    la_ = self._interp.adaptivePredict(self._input,18,self._ctx)
                    if la_ == 1:
                        localctx = Gramatyka_i_tokenyParser.ValueContext(self, _parentctx, _parentState)
                        self.pushNewRecursionContext(localctx, _startState, self.RULE_value)
                        self.state = 191
                        if not self.precpred(self._ctx, 13):
                            from antlr4.error.Errors import FailedPredicateException
                            raise FailedPredicateException(self, "self.precpred(self._ctx, 13)")
                        self.state = 192
                        _la = self._input.LA(1)
                        if not(_la==16 or _la==34):
                            self._errHandler.recoverInline(self)
                        else:
                            self._errHandler.reportMatch(self)
                            self.consume()
                        self.state = 193
                        self.value(14)
                        pass

                    elif la_ == 2:
                        localctx = Gramatyka_i_tokenyParser.ValueContext(self, _parentctx, _parentState)
                        self.pushNewRecursionContext(localctx, _startState, self.RULE_value)
                        self.state = 194
                        if not self.precpred(self._ctx, 12):
                            from antlr4.error.Errors import FailedPredicateException
                            raise FailedPredicateException(self, "self.precpred(self._ctx, 12)")
                        self.state = 195
                        _la = self._input.LA(1)
                        if not((((_la) & ~0x3f) == 0 and ((1 << _la) & 240518168576) != 0)):
                            self._errHandler.recoverInline(self)
                        else:
                            self._errHandler.reportMatch(self)
                            self.consume()
                        self.state = 196
                        self.value(13)
                        pass

                    elif la_ == 3:
                        localctx = Gramatyka_i_tokenyParser.ValueContext(self, _parentctx, _parentState)
                        self.pushNewRecursionContext(localctx, _startState, self.RULE_value)
                        self.state = 197
                        if not self.precpred(self._ctx, 11):
                            from antlr4.error.Errors import FailedPredicateException
                            raise FailedPredicateException(self, "self.precpred(self._ctx, 11)")
                        self.state = 198
                        _la = self._input.LA(1)
                        if not(_la==38 or _la==39):
                            self._errHandler.recoverInline(self)
                        else:
                            self._errHandler.reportMatch(self)
                            self.consume()
                        self.state = 199
                        self.value(12)
                        pass

                    elif la_ == 4:
                        localctx = Gramatyka_i_tokenyParser.ValueContext(self, _parentctx, _parentState)
                        self.pushNewRecursionContext(localctx, _startState, self.RULE_value)
                        self.state = 200
                        if not self.precpred(self._ctx, 10):
                            from antlr4.error.Errors import FailedPredicateException
                            raise FailedPredicateException(self, "self.precpred(self._ctx, 10)")
                        self.state = 201
                        _la = self._input.LA(1)
                        if not((((_la) & ~0x3f) == 0 and ((1 << _la) & 16492674416640) != 0)):
                            self._errHandler.recoverInline(self)
                        else:
                            self._errHandler.reportMatch(self)
                            self.consume()
                        self.state = 202
                        self.value(11)
                        pass

                    elif la_ == 5:
                        localctx = Gramatyka_i_tokenyParser.ValueContext(self, _parentctx, _parentState)
                        self.pushNewRecursionContext(localctx, _startState, self.RULE_value)
                        self.state = 203
                        if not self.precpred(self._ctx, 9):
                            from antlr4.error.Errors import FailedPredicateException
                            raise FailedPredicateException(self, "self.precpred(self._ctx, 9)")
                        self.state = 204
                        self.match(Gramatyka_i_tokenyParser.AND)
                        self.state = 205
                        self.value(10)
                        pass

                    elif la_ == 6:
                        localctx = Gramatyka_i_tokenyParser.ValueContext(self, _parentctx, _parentState)
                        self.pushNewRecursionContext(localctx, _startState, self.RULE_value)
                        self.state = 206
                        if not self.precpred(self._ctx, 8):
                            from antlr4.error.Errors import FailedPredicateException
                            raise FailedPredicateException(self, "self.precpred(self._ctx, 8)")
                        self.state = 207
                        self.match(Gramatyka_i_tokenyParser.OR)
                        self.state = 208
                        self.value(9)
                        pass

                    elif la_ == 7:
                        localctx = Gramatyka_i_tokenyParser.ValueContext(self, _parentctx, _parentState)
                        self.pushNewRecursionContext(localctx, _startState, self.RULE_value)
                        self.state = 209
                        if not self.precpred(self._ctx, 7):
                            from antlr4.error.Errors import FailedPredicateException
                            raise FailedPredicateException(self, "self.precpred(self._ctx, 7)")
                        self.state = 210
                        self.match(Gramatyka_i_tokenyParser.ASSIGN)
                        self.state = 211
                        self.value(8)
                        pass

                    elif la_ == 8:
                        localctx = Gramatyka_i_tokenyParser.ValueContext(self, _parentctx, _parentState)
                        self.pushNewRecursionContext(localctx, _startState, self.RULE_value)
                        self.state = 212
                        if not self.precpred(self._ctx, 6):
                            from antlr4.error.Errors import FailedPredicateException
                            raise FailedPredicateException(self, "self.precpred(self._ctx, 6)")
                        self.state = 213
                        self.match(Gramatyka_i_tokenyParser.COMMA)
                        self.state = 214
                        self.value(7)
                        pass

             
                self.state = 219
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,19,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.unrollRecursionContexts(_parentctx)
        return localctx


    class IdentifierContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def IDENTIFIER(self):
            return self.getToken(Gramatyka_i_tokenyParser.IDENTIFIER, 0)

        def getRuleIndex(self):
            return Gramatyka_i_tokenyParser.RULE_identifier

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterIdentifier" ):
                listener.enterIdentifier(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitIdentifier" ):
                listener.exitIdentifier(self)




    def identifier(self):

        localctx = Gramatyka_i_tokenyParser.IdentifierContext(self, self._ctx, self.state)
        self.enterRule(localctx, 24, self.RULE_identifier)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 220
            self.match(Gramatyka_i_tokenyParser.IDENTIFIER)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx



    def sempred(self, localctx:RuleContext, ruleIndex:int, predIndex:int):
        if self._predicates == None:
            self._predicates = dict()
        self._predicates[11] = self.value_sempred
        pred = self._predicates.get(ruleIndex, None)
        if pred is None:
            raise Exception("No predicate with index:" + str(ruleIndex))
        else:
            return pred(localctx, predIndex)

    def value_sempred(self, localctx:ValueContext, predIndex:int):
            if predIndex == 0:
                return self.precpred(self._ctx, 13)
         

            if predIndex == 1:
                return self.precpred(self._ctx, 12)
         

            if predIndex == 2:
                return self.precpred(self._ctx, 11)
         

            if predIndex == 3:
                return self.precpred(self._ctx, 10)
         

            if predIndex == 4:
                return self.precpred(self._ctx, 9)
         

            if predIndex == 5:
                return self.precpred(self._ctx, 8)
         

            if predIndex == 6:
                return self.precpred(self._ctx, 7)
         

            if predIndex == 7:
                return self.precpred(self._ctx, 6)
         




